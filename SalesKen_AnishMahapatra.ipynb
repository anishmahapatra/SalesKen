{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"SalesKen.png\" alt=\"upGrad\" align=\"Left\" style=\"width: 200px;\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SalesKen Data Science Test\n",
    "<i><b>Author: Anish Mahapatra</i></b>\n",
    "\n",
    "<i>Date: 01-Feb-2019</i>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Problem Statement - 1: Matching the misspelt cities.\n",
    "There are two data files (.csv)\n",
    "\n",
    "<b>Correct_cities.csv</b> : This file consists of a list of cities and they are spelt correctly. It has three columns \"name\" which is a city name; \"country\" where the city belongs to and \"id\" which is a unique id for each city.\n",
    "\n",
    "<b>Misspelt_cities.csv</b> : This file consists of city names which are mispelt. Each city name has been misspelt by randomly replacing 20% of the characters by some random characters. It has two columns \"misspelt_name\" and \"country\".\n",
    "\n",
    "Question : Write an algorithm or a group of algorithms to match the misspelt city name with the correct city name and return the list of unique ids for each misspelt city name.\n",
    "\n",
    "For example : Correct Data -> (Bangalore, India, 101) and say for \"Bangalore\" the misspelt name is (Banhakorg, India). Then the matching algorithm should return 101 for this example."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Approach 1:</b>\n",
    "\n",
    "Steps to be followed to find and perform partial match:\n",
    "- Read the correct_cities.csv and misspelt_cities.csv file as a pandas dataframe\n",
    "    - Sense check of the data\n",
    "    - Check the shape of the data\n",
    "    - check for missing values (NaN)\n",
    "- By country, iterate through the cities and compute the similarity score (Levensthein using fuzzywuzzy)\n",
    "    - Substeps for similarity: convert to lower case, find the partial match score\n",
    "- Set the threshold for the similariity score\n",
    "- If the similarity score is greater than threshold, assign the id from the correct_cities onto the misspelt_cities file\n",
    "\n",
    "<b>Next Steps:</b>\n",
    "1. Look at the misspelt cities that still do not have an id\n",
    "2. Use a different algorithm to perform partial text match on the files\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Packages to be imported\n",
    "import matplotlib.pyplot as plt\n",
    "from fuzzywuzzy import process\n",
    "from fuzzywuzzy import fuzz \n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reading the csv files\n",
    "correctCities = pd.read_csv(\"Correct_cities.csv\")\n",
    "misspeltCities = pd.read_csv(\"Misspelt_cities.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Correct cities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>country</th>\n",
       "      <th>id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>les Escaldes</td>\n",
       "      <td>Andorra</td>\n",
       "      <td>3040051</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Andorra la Vella</td>\n",
       "      <td>Andorra</td>\n",
       "      <td>3041563</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Umm al Qaywayn</td>\n",
       "      <td>United Arab Emirates</td>\n",
       "      <td>290594</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Ras al-Khaimah</td>\n",
       "      <td>United Arab Emirates</td>\n",
       "      <td>291074</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Khawr Fakkān</td>\n",
       "      <td>United Arab Emirates</td>\n",
       "      <td>291696</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               name               country       id\n",
       "0      les Escaldes               Andorra  3040051\n",
       "1  Andorra la Vella               Andorra  3041563\n",
       "2    Umm al Qaywayn  United Arab Emirates   290594\n",
       "3    Ras al-Khaimah  United Arab Emirates   291074\n",
       "4      Khawr Fakkān  United Arab Emirates   291696"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Sense check of the data\n",
    "correctCities.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(23018, 3)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Shape of the data\n",
    "correctCities.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "name       0\n",
       "country    0\n",
       "id         0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Checking for missing values\n",
    "correctCities.isnull().sum(axis = 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Misspelt Cities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>misspelt_name</th>\n",
       "      <th>country</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Hfjdúszoposzló</td>\n",
       "      <td>Hungary</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Otrajnyy</td>\n",
       "      <td>Russia</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ian Isidre</td>\n",
       "      <td>Peru</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Bordj Zemoufa</td>\n",
       "      <td>Algeria</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ChulamViwta</td>\n",
       "      <td>United States</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    misspelt_name        country\n",
       "0  Hfjdúszoposzló        Hungary\n",
       "1        Otrajnyy         Russia\n",
       "2      ian Isidre           Peru\n",
       "3   Bordj Zemoufa        Algeria\n",
       "4     ChulamViwta  United States"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Sense check of the data\n",
    "misspeltCities.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(23018, 2)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "misspeltCities.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "misspelt_name    0\n",
       "country          0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Checking for missing values\n",
    "misspeltCities.isnull().sum(axis = 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Awesome! \n",
    "\n",
    "Now we know that the shape of the data for both the data frames is the same and we should be able to match the correct files with the corrupted ones."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Let's convert the misspelt names and correct names to lowercase to ensure that the scores have inegrity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0            les escaldes\n",
       "1        andorra la vella\n",
       "2          umm al qaywayn\n",
       "3          ras al-khaimah\n",
       "4            khawr fakkān\n",
       "               ...       \n",
       "23013            bulawayo\n",
       "23014             bindura\n",
       "23015          beitbridge\n",
       "23016             epworth\n",
       "23017         chitungwiza\n",
       "Name: name, Length: 23018, dtype: object"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Converting the column to lower case'\n",
    "correctCities['name'].str.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        hfjdúszoposzló\n",
       "1              otrajnyy\n",
       "2            ian isidre\n",
       "3         bordj zemoufa\n",
       "4           chulamviwta\n",
       "              ...      \n",
       "23013        zdigulegsk\n",
       "23014            ygring\n",
       "23015         moudougou\n",
       "23016            bhīkxi\n",
       "23017    belvfbere park\n",
       "Name: misspelt_name, Length: 23018, dtype: object"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Converting the column to lower case'\n",
    "misspeltCities['misspelt_name'].str.lower()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's now feed this back to the original dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feeding lower case back to original dataframe\n",
    "correctCities['name'] = correctCities['name'].str.lower()\n",
    "misspeltCities['misspelt_name'] = misspeltCities['misspelt_name'].str.lower()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fuzzywuzzy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "59"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Sense check to generate the score between two strings\n",
    "fuzz.ratio(\"SalesKen\",\"Slaeeenek\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "62"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Sense check to generate the partial score between two strings\n",
    "fuzz.partial_ratio(\"SalesKen\",\"Slaeeenek\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We shall be using the **fuzz.ratio** function as the order of the cities will remain the same "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to check get the scores\n",
    "def checker(wrong_options,correct_options):\n",
    "    names_array=[]\n",
    "    ratio_array=[]    \n",
    "    for wrong_option in wrong_options:\n",
    "        if wrong_option in correct_options:\n",
    "            names_array.append(wrong_option)\n",
    "            ratio_array.append('100')\n",
    "        else:   \n",
    "            x=process.extractOne(wrong_option,correct_options,scorer=fuzz.token_set_ratio)\n",
    "            names_array.append(x[0])\n",
    "            ratio_array.append(x[1])\n",
    "    return names_array,ratio_array"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Taking the columns to be matched and converting them to a list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Styling:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>.dataframe th, td:first-child{background:#3f577c;font-family:monospace;color:white;border:3px solid white;\n",
       "text-align:left !important;}#codex{float:right;}</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%HTML\n",
    "<style>.dataframe th, td:first-child{background:#3f577c;font-family:monospace;color:white;border:3px solid white;\n",
    "text-align:left !important;}#codex{float:right;}</style>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>country</th>\n",
       "      <th>id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>les escaldes</td>\n",
       "      <td>Andorra</td>\n",
       "      <td>3040051</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>andorra la vella</td>\n",
       "      <td>Andorra</td>\n",
       "      <td>3041563</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>umm al qaywayn</td>\n",
       "      <td>United Arab Emirates</td>\n",
       "      <td>290594</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               name               country       id\n",
       "0      les escaldes               Andorra  3040051\n",
       "1  andorra la vella               Andorra  3041563\n",
       "2    umm al qaywayn  United Arab Emirates   290594"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "correctCities.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>misspelt_name</th>\n",
       "      <th>country</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>hfjdúszoposzló</td>\n",
       "      <td>Hungary</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>otrajnyy</td>\n",
       "      <td>Russia</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ian isidre</td>\n",
       "      <td>Peru</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    misspelt_name  country\n",
       "0  hfjdúszoposzló  Hungary\n",
       "1        otrajnyy   Russia\n",
       "2      ian isidre     Peru"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "misspeltCities.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reading a sample csv file\n",
    "df = pd.read_csv('test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>correctname</th>\n",
       "      <th>wrongcityname</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [correctname, wrongcityname]\n",
       "Index: []"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Sense check of the data\n",
    "df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Making a new dataframe, where we shall add the similarity score \n",
    "df['correctname'] = correctCities['name']\n",
    "df['wrongcityname'] = misspeltCities['misspelt_name']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Using the function to match \n",
    "# name_match,ratio_match=checker(misspeltCitiesList,correctCitiesList)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df1 = pd.DataFrame()\n",
    "# df1['old_names']=pd.Series(str2Match)\n",
    "# df1['correct_names']=pd.Series(name_match)\n",
    "# df1['correct_ratio']=pd.Series(ratio_match)\n",
    "# df1.to_excel('matched_names.xlsx', engine='xlsxwriter')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here, we have tried two approaches:\n",
    "1. Using the Levensthein formula \n",
    "2. Using the FuzzyWuzzy package\n",
    "\n",
    "The output of the code is to give us a similarity score. We should iterate it by country, else it becomes inefficient as it ha a score of O(n^2) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is taking more time than we have, as a competency showcase, let us try to do it for the country Australia"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "australia = pd.read_csv('Australia.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>correctname</th>\n",
       "      <th>country</th>\n",
       "      <th>correctid</th>\n",
       "      <th>wrongname</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Whyalla</td>\n",
       "      <td>Australia</td>\n",
       "      <td>2058430</td>\n",
       "      <td>Esrlwood</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Rockingham</td>\n",
       "      <td>Australia</td>\n",
       "      <td>2062338</td>\n",
       "      <td>Gleoroy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Prospect</td>\n",
       "      <td>Australia</td>\n",
       "      <td>2062944</td>\n",
       "      <td>Sundury</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Port Hedland</td>\n",
       "      <td>Australia</td>\n",
       "      <td>2063042</td>\n",
       "      <td>Armakale</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Perth</td>\n",
       "      <td>Australia</td>\n",
       "      <td>2063523</td>\n",
       "      <td>Caloundfa</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    correctname    country  correctid  wrongname\n",
       "0       Whyalla  Australia    2058430   Esrlwood\n",
       "1    Rockingham  Australia    2062338    Gleoroy\n",
       "2      Prospect  Australia    2062944    Sundury\n",
       "3  Port Hedland  Australia    2063042   Armakale\n",
       "4         Perth  Australia    2063523  Caloundfa"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "australia.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to get the similarity score of the correct city name and the wrong city name\n",
    "correct_name = []\n",
    "similarity = []\n",
    "\n",
    "for i in australia.correctname:\n",
    "    ratio = process.extract( i, australia.wrongname, limit=1)\n",
    "    correct_name.append(ratio[0][0])\n",
    "    similarity.append(ratio[0][1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adding the similarity score\n",
    "australia['similarity'] = pd.Series(similarity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>correctname</th>\n",
       "      <th>country</th>\n",
       "      <th>correctid</th>\n",
       "      <th>wrongname</th>\n",
       "      <th>similarity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Whyalla</td>\n",
       "      <td>Australia</td>\n",
       "      <td>2058430</td>\n",
       "      <td>Esrlwood</td>\n",
       "      <td>86</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Rockingham</td>\n",
       "      <td>Australia</td>\n",
       "      <td>2062338</td>\n",
       "      <td>Gleoroy</td>\n",
       "      <td>80</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Prospect</td>\n",
       "      <td>Australia</td>\n",
       "      <td>2062944</td>\n",
       "      <td>Sundury</td>\n",
       "      <td>88</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  correctname    country  correctid wrongname  similarity\n",
       "0     Whyalla  Australia    2058430  Esrlwood          86\n",
       "1  Rockingham  Australia    2062338   Gleoroy          80\n",
       "2    Prospect  Australia    2062944   Sundury          88"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_result_australia = australia[['correctname', 'country', 'correctid', 'wrongname', 'similarity']]\n",
    "final_result_australia.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style  type=\"text/css\" >\n",
       "    #T_69e6714a_44d4_11ea_a384_f430b9aee9c3row0_col4 {\n",
       "            background-color:  #7fbf66;\n",
       "            color:  #000000;\n",
       "        }    #T_69e6714a_44d4_11ea_a384_f430b9aee9c3row1_col4 {\n",
       "            background-color:  #ffff66;\n",
       "            color:  #000000;\n",
       "        }    #T_69e6714a_44d4_11ea_a384_f430b9aee9c3row2_col4 {\n",
       "            background-color:  #55aa66;\n",
       "            color:  #000000;\n",
       "        }    #T_69e6714a_44d4_11ea_a384_f430b9aee9c3row3_col4 {\n",
       "            background-color:  #bfdf66;\n",
       "            color:  #000000;\n",
       "        }    #T_69e6714a_44d4_11ea_a384_f430b9aee9c3row4_col4 {\n",
       "            background-color:  #ffff66;\n",
       "            color:  #000000;\n",
       "        }    #T_69e6714a_44d4_11ea_a384_f430b9aee9c3row5_col4 {\n",
       "            background-color:  #95ca66;\n",
       "            color:  #000000;\n",
       "        }    #T_69e6714a_44d4_11ea_a384_f430b9aee9c3row6_col4 {\n",
       "            background-color:  #3f9f66;\n",
       "            color:  #000000;\n",
       "        }    #T_69e6714a_44d4_11ea_a384_f430b9aee9c3row7_col4 {\n",
       "            background-color:  #008066;\n",
       "            color:  #f1f1f1;\n",
       "        }</style><table id=\"T_69e6714a_44d4_11ea_a384_f430b9aee9c3\" ><thead>    <tr>        <th class=\"blank level0\" ></th>        <th class=\"col_heading level0 col0\" >correctname</th>        <th class=\"col_heading level0 col1\" >country</th>        <th class=\"col_heading level0 col2\" >correctid</th>        <th class=\"col_heading level0 col3\" >wrongname</th>        <th class=\"col_heading level0 col4\" >similarity</th>    </tr></thead><tbody>\n",
       "                <tr>\n",
       "                        <th id=\"T_69e6714a_44d4_11ea_a384_f430b9aee9c3level0_row0\" class=\"row_heading level0 row0\" >0</th>\n",
       "                        <td id=\"T_69e6714a_44d4_11ea_a384_f430b9aee9c3row0_col0\" class=\"data row0 col0\" >Whyalla</td>\n",
       "                        <td id=\"T_69e6714a_44d4_11ea_a384_f430b9aee9c3row0_col1\" class=\"data row0 col1\" >Australia</td>\n",
       "                        <td id=\"T_69e6714a_44d4_11ea_a384_f430b9aee9c3row0_col2\" class=\"data row0 col2\" >2058430</td>\n",
       "                        <td id=\"T_69e6714a_44d4_11ea_a384_f430b9aee9c3row0_col3\" class=\"data row0 col3\" >Esrlwood</td>\n",
       "                        <td id=\"T_69e6714a_44d4_11ea_a384_f430b9aee9c3row0_col4\" class=\"data row0 col4\" >86</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_69e6714a_44d4_11ea_a384_f430b9aee9c3level0_row1\" class=\"row_heading level0 row1\" >1</th>\n",
       "                        <td id=\"T_69e6714a_44d4_11ea_a384_f430b9aee9c3row1_col0\" class=\"data row1 col0\" >Rockingham</td>\n",
       "                        <td id=\"T_69e6714a_44d4_11ea_a384_f430b9aee9c3row1_col1\" class=\"data row1 col1\" >Australia</td>\n",
       "                        <td id=\"T_69e6714a_44d4_11ea_a384_f430b9aee9c3row1_col2\" class=\"data row1 col2\" >2062338</td>\n",
       "                        <td id=\"T_69e6714a_44d4_11ea_a384_f430b9aee9c3row1_col3\" class=\"data row1 col3\" >Gleoroy</td>\n",
       "                        <td id=\"T_69e6714a_44d4_11ea_a384_f430b9aee9c3row1_col4\" class=\"data row1 col4\" >80</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_69e6714a_44d4_11ea_a384_f430b9aee9c3level0_row2\" class=\"row_heading level0 row2\" >2</th>\n",
       "                        <td id=\"T_69e6714a_44d4_11ea_a384_f430b9aee9c3row2_col0\" class=\"data row2 col0\" >Prospect</td>\n",
       "                        <td id=\"T_69e6714a_44d4_11ea_a384_f430b9aee9c3row2_col1\" class=\"data row2 col1\" >Australia</td>\n",
       "                        <td id=\"T_69e6714a_44d4_11ea_a384_f430b9aee9c3row2_col2\" class=\"data row2 col2\" >2062944</td>\n",
       "                        <td id=\"T_69e6714a_44d4_11ea_a384_f430b9aee9c3row2_col3\" class=\"data row2 col3\" >Sundury</td>\n",
       "                        <td id=\"T_69e6714a_44d4_11ea_a384_f430b9aee9c3row2_col4\" class=\"data row2 col4\" >88</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_69e6714a_44d4_11ea_a384_f430b9aee9c3level0_row3\" class=\"row_heading level0 row3\" >3</th>\n",
       "                        <td id=\"T_69e6714a_44d4_11ea_a384_f430b9aee9c3row3_col0\" class=\"data row3 col0\" >Port Hedland</td>\n",
       "                        <td id=\"T_69e6714a_44d4_11ea_a384_f430b9aee9c3row3_col1\" class=\"data row3 col1\" >Australia</td>\n",
       "                        <td id=\"T_69e6714a_44d4_11ea_a384_f430b9aee9c3row3_col2\" class=\"data row3 col2\" >2063042</td>\n",
       "                        <td id=\"T_69e6714a_44d4_11ea_a384_f430b9aee9c3row3_col3\" class=\"data row3 col3\" >Armakale</td>\n",
       "                        <td id=\"T_69e6714a_44d4_11ea_a384_f430b9aee9c3row3_col4\" class=\"data row3 col4\" >83</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_69e6714a_44d4_11ea_a384_f430b9aee9c3level0_row4\" class=\"row_heading level0 row4\" >4</th>\n",
       "                        <td id=\"T_69e6714a_44d4_11ea_a384_f430b9aee9c3row4_col0\" class=\"data row4 col0\" >Perth</td>\n",
       "                        <td id=\"T_69e6714a_44d4_11ea_a384_f430b9aee9c3row4_col1\" class=\"data row4 col1\" >Australia</td>\n",
       "                        <td id=\"T_69e6714a_44d4_11ea_a384_f430b9aee9c3row4_col2\" class=\"data row4 col2\" >2063523</td>\n",
       "                        <td id=\"T_69e6714a_44d4_11ea_a384_f430b9aee9c3row4_col3\" class=\"data row4 col3\" >Caloundfa</td>\n",
       "                        <td id=\"T_69e6714a_44d4_11ea_a384_f430b9aee9c3row4_col4\" class=\"data row4 col4\" >80</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_69e6714a_44d4_11ea_a384_f430b9aee9c3level0_row5\" class=\"row_heading level0 row5\" >5</th>\n",
       "                        <td id=\"T_69e6714a_44d4_11ea_a384_f430b9aee9c3row5_col0\" class=\"data row5 col0\" >Murray Bridge</td>\n",
       "                        <td id=\"T_69e6714a_44d4_11ea_a384_f430b9aee9c3row5_col1\" class=\"data row5 col1\" >Australia</td>\n",
       "                        <td id=\"T_69e6714a_44d4_11ea_a384_f430b9aee9c3row5_col2\" class=\"data row5 col2\" >2065176</td>\n",
       "                        <td id=\"T_69e6714a_44d4_11ea_a384_f430b9aee9c3row5_col3\" class=\"data row5 col3\" >Craigibbzrn</td>\n",
       "                        <td id=\"T_69e6714a_44d4_11ea_a384_f430b9aee9c3row5_col4\" class=\"data row5 col4\" >85</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_69e6714a_44d4_11ea_a384_f430b9aee9c3level0_row6\" class=\"row_heading level0 row6\" >6</th>\n",
       "                        <td id=\"T_69e6714a_44d4_11ea_a384_f430b9aee9c3row6_col0\" class=\"data row6 col0\" >Mount Isa</td>\n",
       "                        <td id=\"T_69e6714a_44d4_11ea_a384_f430b9aee9c3row6_col1\" class=\"data row6 col1\" >Australia</td>\n",
       "                        <td id=\"T_69e6714a_44d4_11ea_a384_f430b9aee9c3row6_col2\" class=\"data row6 col2\" >2065594</td>\n",
       "                        <td id=\"T_69e6714a_44d4_11ea_a384_f430b9aee9c3row6_col3\" class=\"data row6 col3\" >Melbournk</td>\n",
       "                        <td id=\"T_69e6714a_44d4_11ea_a384_f430b9aee9c3row6_col4\" class=\"data row6 col4\" >89</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_69e6714a_44d4_11ea_a384_f430b9aee9c3level0_row7\" class=\"row_heading level0 row7\" >7</th>\n",
       "                        <td id=\"T_69e6714a_44d4_11ea_a384_f430b9aee9c3row7_col0\" class=\"data row7 col0\" >Morphett Vale</td>\n",
       "                        <td id=\"T_69e6714a_44d4_11ea_a384_f430b9aee9c3row7_col1\" class=\"data row7 col1\" >Australia</td>\n",
       "                        <td id=\"T_69e6714a_44d4_11ea_a384_f430b9aee9c3row7_col2\" class=\"data row7 col2\" >2065740</td>\n",
       "                        <td id=\"T_69e6714a_44d4_11ea_a384_f430b9aee9c3row7_col3\" class=\"data row7 col3\" >South Grscton</td>\n",
       "                        <td id=\"T_69e6714a_44d4_11ea_a384_f430b9aee9c3row7_col4\" class=\"data row7 col4\" >92</td>\n",
       "            </tr>\n",
       "    </tbody></table>"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x1e71bc3ec88>"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_result_australia.head(8).style.background_gradient(subset='similarity',\n",
    "                                               cmap='summer_r')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>correctname</th>\n",
       "      <th>country</th>\n",
       "      <th>correctid</th>\n",
       "      <th>wrongname</th>\n",
       "      <th>similarity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Whyalla</td>\n",
       "      <td>Australia</td>\n",
       "      <td>2058430</td>\n",
       "      <td>Esrlwood</td>\n",
       "      <td>86</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Rockingham</td>\n",
       "      <td>Australia</td>\n",
       "      <td>2062338</td>\n",
       "      <td>Gleoroy</td>\n",
       "      <td>80</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Prospect</td>\n",
       "      <td>Australia</td>\n",
       "      <td>2062944</td>\n",
       "      <td>Sundury</td>\n",
       "      <td>88</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Port Hedland</td>\n",
       "      <td>Australia</td>\n",
       "      <td>2063042</td>\n",
       "      <td>Armakale</td>\n",
       "      <td>83</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Perth</td>\n",
       "      <td>Australia</td>\n",
       "      <td>2063523</td>\n",
       "      <td>Caloundfa</td>\n",
       "      <td>80</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    correctname    country  correctid  wrongname  similarity\n",
       "0       Whyalla  Australia    2058430   Esrlwood          86\n",
       "1    Rockingham  Australia    2062338    Gleoroy          80\n",
       "2      Prospect  Australia    2062944    Sundury          88\n",
       "3  Port Hedland  Australia    2063042   Armakale          83\n",
       "4         Perth  Australia    2063523  Caloundfa          80"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "australia.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "hashdict = dict(zip(australia['correctid'], australia['correctname']))\n",
    "\n",
    "def checkpair (a,b,l):\n",
    "    for x in l:\n",
    "        if (a,b) == (x[2],x[0]):\n",
    "            l.remove(x)\n",
    "\n",
    "matches = []\n",
    "for k,v in hashdict.items():\n",
    "\n",
    "    #see docs for extract -- 4 because you are comparing a name to itself\n",
    "    top3 = process.extract(v, hashdict, limit=4)\n",
    "\n",
    "    #remove the hashID compared to itself\n",
    "    for h in top3:\n",
    "        if k == h[2]:\n",
    "            top3.remove(h)\n",
    "\n",
    "    #append tuples to the list \"matches\" if it meets a score criteria      \n",
    "    [matches.append((k, v, x[2], x[0], x[1])) for x in top3 if x[1] > 60] #change score?\n",
    "\n",
    "    #remove reciprocal pairs\n",
    "    [checkpair(m[0], m[2], matches) for m in matches]\n",
    "\n",
    "df = pd.DataFrame(matches, columns=['original_id', 'correct_city_name', 'mapped_id', 'misspelt_city', 'score'])\n",
    "#writer = pd.ExcelWriter('C:\\\\Users\\\\HP\\\\Desktop\\\\SalesKen Test\\\\SaleskenProblemSolving-master\\\\03AustraliaAnswer.xlsx')\n",
    "# df.to_excel(writer,'Sheet1')\n",
    "# writer.save()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>original_id</th>\n",
       "      <th>correct_city_name</th>\n",
       "      <th>mapped_id</th>\n",
       "      <th>misspelt_city</th>\n",
       "      <th>score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2062338</td>\n",
       "      <td>Rockingham</td>\n",
       "      <td>2151437</td>\n",
       "      <td>Rockhampton</td>\n",
       "      <td>67</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2063042</td>\n",
       "      <td>Port Hedland</td>\n",
       "      <td>2148398</td>\n",
       "      <td>Port Stephens</td>\n",
       "      <td>64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2065176</td>\n",
       "      <td>Murray Bridge</td>\n",
       "      <td>6943558</td>\n",
       "      <td>Bracken Ridge</td>\n",
       "      <td>62</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2065594</td>\n",
       "      <td>Mount Isa</td>\n",
       "      <td>2156663</td>\n",
       "      <td>Mount Eliza</td>\n",
       "      <td>80</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2065594</td>\n",
       "      <td>Mount Isa</td>\n",
       "      <td>2156578</td>\n",
       "      <td>Mount Martha</td>\n",
       "      <td>67</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   original_id correct_city_name  mapped_id  misspelt_city  score\n",
       "0      2062338        Rockingham    2151437    Rockhampton     67\n",
       "1      2063042      Port Hedland    2148398  Port Stephens     64\n",
       "2      2065176     Murray Bridge    6943558  Bracken Ridge     62\n",
       "3      2065594         Mount Isa    2156663    Mount Eliza     80\n",
       "4      2065594         Mount Isa    2156578   Mount Martha     67"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Great, we have now got a similarity score for Australia!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we need to map the correctid, which is the id of the correct cities to the wrong name"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's now try a different approach to get the unique ids\n",
    "def checkpair (a,b,l):\n",
    "    for x in l:\n",
    "        if (a,b) == (x[2],x[0]):\n",
    "            l.remove(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = australia.copy(deep=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>correctname</th>\n",
       "      <th>country</th>\n",
       "      <th>correctid</th>\n",
       "      <th>wrongname</th>\n",
       "      <th>similarity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Whyalla</td>\n",
       "      <td>Australia</td>\n",
       "      <td>2058430</td>\n",
       "      <td>Esrlwood</td>\n",
       "      <td>86</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Rockingham</td>\n",
       "      <td>Australia</td>\n",
       "      <td>2062338</td>\n",
       "      <td>Gleoroy</td>\n",
       "      <td>80</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Prospect</td>\n",
       "      <td>Australia</td>\n",
       "      <td>2062944</td>\n",
       "      <td>Sundury</td>\n",
       "      <td>88</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Port Hedland</td>\n",
       "      <td>Australia</td>\n",
       "      <td>2063042</td>\n",
       "      <td>Armakale</td>\n",
       "      <td>83</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Perth</td>\n",
       "      <td>Australia</td>\n",
       "      <td>2063523</td>\n",
       "      <td>Caloundfa</td>\n",
       "      <td>80</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    correctname    country  correctid  wrongname  similarity\n",
       "0       Whyalla  Australia    2058430   Esrlwood          86\n",
       "1    Rockingham  Australia    2062338    Gleoroy          80\n",
       "2      Prospect  Australia    2062944    Sundury          88\n",
       "3  Port Hedland  Australia    2063042   Armakale          83\n",
       "4         Perth  Australia    2063523  Caloundfa          80"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "result [(86, 'Whyrlla')]\n",
      "Best M=Whyrlla\n",
      "result [(60, 'kmina'), (80, 'Rocpbngham')]\n",
      "Best M=Rocpbngham\n",
      "result [(88, 'Pronpect')]\n",
      "Best M=Pronpect\n",
      "result [(53, 'Adelakde'), (56, 'St qlbans'), (60, 'Pertx'), (83, 'Pork Hedlanw')]\n",
      "Best M=Pork Hedlanw\n",
      "result [(60, 'Caeberwhll'), (60, 'Cheltdhham'), (60, 'Ferntree dwlly'), (60, 'NoblevParh'), (60, 'Northcotp'), (60, 'Nxrth fyde'), (60, 'PortwStlphens'), (60, 'Willethon'), (60, 'palmermton'), (80, 'Pertx')]\n",
      "Best M=Pertx\n",
      "result [(56, 'Wotdridge'), (85, 'burrav Bridge')]\n",
      "Best M=burrav Bridge\n",
      "result [(56, 'South Grscton'), (67, 'Moe'), (67, 'Mount Elwda'), (67, 'iount Galbier'), (78, 'Mount Martrj'), (89, 'MountmIsa')]\n",
      "Best M=MountmIsa\n",
      "result [(55, 'Forest aoke'), (67, 'Moe'), (92, 'MorphetutVale')]\n",
      "Best M=MorphetutVale\n",
      "result [(57, 'Sundury'), (57, 'qildura'), (88, 'Mabdurah')]\n",
      "Best M=Mabdurah\n",
      "result [(60, 'kmina'), (67, 'Kew'), (100, 'Kwinana')]\n",
      "Best M=Kwinana\n",
      "result [(60, 'Lalon'), (80, 'Ktlgofrlie')]\n",
      "Best M=Ktlgofrlie\n",
      "result [(88, 'Gvsnells')]\n",
      "Best M=Gvsnells\n",
      "result [(56, 'Granvilld'), (56, 'South Grscton'), (56, 'palmermton'), (56, 'rrankston Eakt'), (56, 'tladstone'), (57, 'zreston'), (59, 'Traralgon'), (60, 'Lalon'), (67, 'kelton'), (89, 'Geraldgon')]\n",
      "Best M=Geraldgon\n",
      "result [(55, 'Acmidale'), (55, 'Armakale'), (55, 'Czrindale'), (55, 'Newcassle'), (55, 'kphingvale'), (55, 'kremantle'), (67, 'Cabowleure'), (67, 'Gleoroy'), (67, 'iount Galbier'), (67, 'palmermton'), (83, 'Gawlnr')]\n",
      "Best M=Gawlnr\n",
      "result [(56, 'Ferntree dwlly'), (56, 'Frankstoc'), (62, 'Armakale'), (89, 'kremantle')]\n",
      "Best M=kremantle\n",
      "result [(67, 'Caringblh'), (67, 'Lxngwarvin'), (67, 'eoppeis Croswing'), (83, 'Dzrwin')]\n",
      "Best M=Dzrwin\n",
      "result [(55, 'Elthao'), (56, 'jrunceston'), (57, 'zreston'), (60, 'Lalon'), (62, 'Gielong'), (83, 'kelton'), (89, 'Busseeton')]\n",
      "Best M=Busseeton\n",
      "result [(57, 'Bunxaberg'), (57, 'Gsulburn'), (57, 'Thornmury'), (62, 'CoffswHurbour'), (67, 'ilbury'), (71, 'Sundury'), (71, 'ihornbury'), (86, 'Bunbuey')]\n",
      "Best M=Bunbuey\n",
      "result [(62, 'Czrindale'), (62, 'kremantle'), (75, 'Acmidale'), (88, 'Armakale')]\n",
      "Best M=Armakale\n",
      "result [(67, 'Emping'), (67, 'Epsing'), (85, 'Adice Sprbngs')]\n",
      "Best M=Adice Sprbngs\n",
      "result [(67, 'St qlbans'), (83, 'Aybany')]\n",
      "Best M=Aybany\n",
      "result [(75, 'udelaixe Hills'), (88, 'Adelakde')]\n",
      "Best M=Adelakde\n",
      "result [(56, 'Wollodgfng'), (56, 'burrav Bridge'), (89, 'Wotdridge')]\n",
      "Best M=Wotdridge\n",
      "result [(57, 'BrightongEasl'), (57, 'Wangarbtaa'), (57, 'Wollodgfng'), (57, 'iandenong Nogeh'), (86, 'Wodongf')]\n",
      "Best M=Wodongf\n",
      "result [(60, 'waree'), (62, 'Ferntree dwlly'), (88, 'Werribme')]\n",
      "Best M=Werribme\n",
      "result [(55, 'Carrum Doods'), (55, 'Wantirna Sopqh'), (91, 'Warrnamboop')]\n",
      "Best M=Warrnamboop\n",
      "result [(55, 'Warrnamboop'), (57, 'Frwkkstln South'), (60, 'kmina'), (64, 'Narhe Wlroen South'), (67, 'nairns'), (74, 'Hankhorn South'), (86, 'Wantirna Sopqh')]\n",
      "Best M=Wantirna Sopqh\n",
      "result [(60, 'Cwty of Parkamctta'), (60, 'Wagga tanga'), (67, 'Parauatta'), (75, 'Lara'), (80, 'Wangarbtaa')]\n",
      "Best M=Wangarbtaa\n",
      "result [(82, 'Wagga tanga')]\n",
      "Best M=Wagga tanga\n",
      "result [(56, 'Carlwxgford'), (56, 'rrankston Eakt'), (67, 'Geraldgon'), (75, 'Lara'), (80, 'Lalon'), (100, 'Traralgon')]\n",
      "Best M=Traralgon\n",
      "result [(56, 'Granvilld'), (57, 'Boronil'), (62, 'Rowvijle'), (80, 'Tofnsvdlle')]\n",
      "Best M=Tofnsvdlle\n",
      "result [(89, 'Toowoomta')]\n",
      "Best M=Toowoomta\n",
      "result [(56, 'Hankhorn South'), (57, 'Bunbuey'), (57, 'Hoansby'), (57, 'Sundury'), (67, 'ilbury'), (89, 'Thornmury'), (89, 'ihornbury')]\n",
      "Best M=ihornbury\n",
      "result [(53, 'Rocuhahpton'), (53, 'South Grscton'), (56, 'Bankstjwn'), (56, 'tladstone'), (57, 'zreston'), (67, 'Bhacktown'), (80, 'Thmmdstown')]\n",
      "Best M=Thmmdstown\n",
      "result [(57, 'Carnegge'), (57, 'Logan Cits'), (57, 'Pronpect'), (57, 'Tamwortp'), (57, 'Thyrnlie'), (57, 'jrunceston'), (60, 'waree'), (71, 'aarnegie'), (100, 'Tarneit')]\n",
      "Best M=Tarneit\n",
      "result [(60, 'Caeberwhll'), (60, 'Carnegge'), (60, 'Ferntree dwlly'), (60, 'Greensuoroumh'), (60, 'HamptonxPare'), (60, 'Namrs Warren'), (60, 'Narhe Wlroen South'), (60, 'Post Macquarie'), (60, 'Traralgon'), (60, 'aarnegie'), (80, 'Tarneit'), (80, 'waree')]\n",
      "Best M=waree\n",
      "result [(57, 'Tarneit'), (88, 'Tamwortp')]\n",
      "Best M=Tamwortp\n",
      "result [(55, 'Engadine'), (83, 'Spdney')]\n",
      "Best M=Spdney\n",
      "result [(67, 'Burnfe'), (67, 'Degr Park'), (75, 'Lara'), (81, 'SurferquParaxise')]\n",
      "Best M=SurferquParaxise\n",
      "result [(56, 'Sunshineavest'), (57, 'Sundury'), (67, 'Aybany'), (89, 'Sunnyback'), (89, 'SunnybinkyHulls')]\n",
      "Best M=SunnybinkyHulls\n",
      "result [(57, 'Gsulburn'), (57, 'Sunnyback'), (57, 'SunnybinkyHulls'), (57, 'Thornmury'), (62, 'CoffswHurbour'), (67, 'ilbury'), (71, 'Bunbuey'), (71, 'ihornbury'), (86, 'Sundury')]\n",
      "Best M=Sundury\n",
      "result [(52, 'Hankhorn South'), (56, 'Northcotp'), (60, 'Pertx'), (85, 'PortwStlphens')]\n",
      "Best M=PortwStlphens\n",
      "result [(53, 'Engadine'), (56, 'Caringblh'), (59, 'Adice Sprbngs'), (60, 'kmina'), (67, 'Czrindale'), (67, 'Emping'), (67, 'Epsing'), (67, 'Orangv'), (80, 'kphingvale')]\n",
      "Best M=kphingvale\n",
      "result [(56, 'Devorport'), (56, 'Frwkkstln South'), (56, 'Hankhorn South'), (56, 'Mount Martrj'), (56, 'Narhe Wlroen South'), (56, 'Northcotp'), (56, 'Rocuhahpton'), (56, 'Shepptrtov'), (67, 'South Grscton'), (67, 'South irisbake'), (89, 'Smuthport')]\n",
      "Best M=Smuthport\n",
      "result [(55, 'Rocuhahpton'), (56, 'Bhacktown'), (56, 'Smuthport'), (57, 'zreston'), (59, 'Geraldgon'), (60, 'Lalon'), (62, 'South irisbake'), (85, 'South Grscton')]\n",
      "Best M=South Grscton\n",
      "result [(56, 'Bhacktown'), (56, 'Smuthport'), (57, 'Shaford'), (57, 'zreston'), (60, 'Lalon'), (60, 'palmermton'), (80, 'Shepptrtov')]\n",
      "Best M=Shepptrtov\n",
      "result [(57, 'Carlwxgford'), (57, 'Endlayour dills'), (57, 'Mafyborougc'), (86, 'Shaford')]\n",
      "Best M=Shaford\n",
      "result [(55, 'Mount Elwda'), (57, 'qildura'), (73, 'Saint tlbass'), (82, 'SaintoKildn')]\n",
      "Best M=SaintoKildn\n",
      "result [(64, 'SaintoKildn'), (67, 'Aybany'), (78, 'St qlbans'), (83, 'Saint tlbass')]\n",
      "Best M=Saint tlbass\n",
      "result [(88, 'Rowvijle')]\n",
      "Best M=Rowvijle\n",
      "result [(53, 'Rimhmond'), (55, 'HamptonxPare'), (56, 'Thmmdstown'), (59, 'Bhacktown'), (60, 'Rocpbngham'), (82, 'Rocuhahpton')]\n",
      "Best M=Rocuhahpton\n",
      "result [(88, 'Rimhmond')]\n",
      "Best M=Rimhmond\n",
      "result [(89, 'Rgservoir')]\n",
      "Best M=Rgservoir\n",
      "result [(57, 'Hoansby'), (62, 'Canberrn'), (71, 'Bunbuey'), (80, 'Queanheyab')]\n",
      "Best M=Queanheyab\n",
      "result [(55, 'gastlenHill'), (58, 'udelaixe Hills'), (64, 'Bckken Hill'), (83, 'Qzasers Hill')]\n",
      "Best M=Qzasers Hill\n",
      "result [(57, 'BrightongEasl'), (57, 'Busseeton'), (57, 'Forest aoke'), (57, 'Pronpect'), (57, 'Thmmdstown'), (57, 'Wevt Pennast'), (57, 'Willethon'), (57, 'palmermton'), (57, 'rrankston Eakt'), (57, 'tladstone'), (60, 'Pertx'), (67, 'kelton'), (71, 'South Grscton'), (71, 'jrunceston'), (86, 'zreston')]\n",
      "Best M=zreston\n",
      "result [(60, 'Pertx'), (60, 'waree'), (62, 'aarnegie'), (93, 'Post Macquarie')]\n",
      "Best M=Post Macquarie\n",
      "result [(90, 'Poidt Cook')]\n",
      "Best M=Poidt Cook\n",
      "result [(57, 'Frwkkstln South'), (57, 'Narhe Wlroen South'), (60, 'kmina'), (64, 'Hankhorn South'), (86, 'Pakenham houtq')]\n",
      "Best M=Pakenham houtq\n",
      "result [(55, 'Btisbane'), (55, 'Mulsrave'), (55, 'Nerana'), (67, 'Carnegge'), (67, 'aarnegie'), (83, 'Orangv')]\n",
      "Best M=Orangv\n",
      "result [(60, 'Bglwyn Noath'), (60, 'Maroabra'), (60, 'Narafgba'), (60, 'Nerana'), (60, 'Newcassle'), (60, 'Northcotp'), (80, 'Noqra')]\n",
      "Best M=Noqra\n",
      "result [(60, 'Noqra'), (67, 'Moe'), (89, 'Northcotp')]\n",
      "Best M=Northcotp\n",
      "result [(56, 'Mill dark'), (60, 'Cwty of Parkamctta'), (60, 'alenmfre Park'), (67, 'Degr Park'), (80, 'NoblevParh')]\n",
      "Best M=NoblevParh\n",
      "result [(56, 'gastlenHill'), (56, 'kremantle'), (67, 'Kew'), (89, 'Newcassle')]\n",
      "Best M=Newcassle\n",
      "result [(55, 'Canberrn'), (60, 'Noqra'), (67, 'Geraldgon'), (67, 'Narafgba'), (67, 'Orangv'), (83, 'Nerana')]\n",
      "Best M=Nerana\n",
      "result [(60, 'waree'), (75, 'Narhe Wlroen South'), (83, 'Namrs Warren')]\n",
      "Best M=Namrs Warren\n",
      "result [(60, 'Noqra'), (62, 'Caringblh'), (62, 'Maroabra'), (62, 'Wangarbtaa'), (67, 'Nerana'), (67, 'Orangv'), (67, 'Wagga tanga'), (75, 'Lara'), (88, 'Narafgba')]\n",
      "Best M=Narafgba\n",
      "result [(55, 'Orangv'), (88, 'Mulsrave')]\n",
      "Best M=Mulsrave\n",
      "result [(53, 'Wangarbtaa'), (58, 'iount Galbier'), (64, 'Mount Elwda'), (67, 'Moe'), (67, 'MountmIsa'), (83, 'Mount Martrj')]\n",
      "Best M=Mount Martrj\n",
      "result [(57, 'Canberrn'), (58, 'Mount Martrj'), (64, 'Mount Elwda'), (67, 'Moe'), (67, 'MountmIsa'), (85, 'iount Galbier')]\n",
      "Best M=iount Galbier\n",
      "result [(55, 'Elthao'), (55, 'South irisbake'), (56, 'MountmIsa'), (64, 'Mount Martrj'), (64, 'iount Galbier'), (67, 'Moe'), (82, 'Mount Elwda')]\n",
      "Best M=Mount Elwda\n",
      "result [(55, 'Bundoosa'), (67, 'Moe'), (83, 'Mosmae')]\n",
      "Best M=Mosmae\n",
      "result [(57, 'Bmndigo'), (57, 'Boronil'), (57, 'Tarneit'), (60, 'BrightongEasl'), (67, 'Moe'), (80, 'worningtin')]\n",
      "Best M=worningtin\n",
      "result [(56, 'Granvilld'), (60, 'Noqra'), (62, 'jshfield'), (67, 'Moe'), (80, 'Mohayfkeld')]\n",
      "Best M=Mohayfkeld\n",
      "result [(67, 'Alpona Meddows'), (67, 'Forest aoke'), (67, 'Melbournk'), (67, 'Mohayfkeld'), (67, 'MorphetutVale'), (67, 'Mosmae'), (67, 'Mount Elwda'), (67, 'Mount Martrj'), (67, 'MountmIsa'), (67, 'Narhe Wlroen South'), (67, 'iandenong Nogeh'), (67, 'tladstone'), (100, 'Moe')]\n",
      "Best M=Moe\n",
      "result [(56, 'Cwty of Parkamctta'), (56, 'Degr Park'), (56, 'alenmfre Park'), (89, 'Mill dark')]\n",
      "Best M=Mill dark\n",
      "result [(57, 'Hillsidu'), (57, 'Melbournk'), (57, 'Mkitland'), (57, 'Mulsrave'), (67, 'ilbury'), (71, 'Mabdurah'), (71, 'Mill dark'), (86, 'qildura')]\n",
      "Best M=qildura\n",
      "result [(60, 'Lalon'), (67, 'Busseeton'), (67, 'Gielong'), (67, 'Melbournk'), (67, 'Moe'), (67, 'Willethon'), (67, 'jrunceston'), (67, 'palmermton'), (67, 'zreston'), (83, 'kelton')]\n",
      "Best M=kelton\n",
      "result [(56, 'Caanyourne'), (56, 'Crfniourne'), (59, 'Cabowleure'), (62, 'Gsulburn'), (67, 'Moe'), (67, 'ilbury'), (73, 'Burnfe'), (89, 'Melbournk')]\n",
      "Best M=Melbournk\n",
      "result [(55, 'Keysborpugo'), (62, 'Maroabra'), (82, 'Mafyborougc')]\n",
      "Best M=Mafyborougc\n",
      "result [(56, 'Granvilld'), (92, 'Marrickvicle')]\n",
      "Best M=Marrickvicle\n",
      "result [(60, 'Noqra'), (62, 'Mabdurah'), (88, 'Maroabra')]\n",
      "Best M=Maroabra\n",
      "result [(88, 'Mkitland')]\n",
      "Best M=Mkitland\n",
      "result [(67, 'Post Macquarie'), (83, 'Mawkay')]\n",
      "Best M=Mawkay\n",
      "result [(89, 'Livergool')]\n",
      "Best M=Livergool\n",
      "result [(57, 'Crfniourne'), (67, 'Moe'), (86, 'Lismorl')]\n",
      "Best M=Lismorl\n",
      "result [(57, 'qildura'), (62, 'Acmidale'), (62, 'Czrindale'), (88, 'Lilydfle')]\n",
      "Best M=Lilydfle\n",
      "result [(56, 'Bankstjwn'), (56, 'Bhacktown'), (56, 'Busseeton'), (56, 'Frankstoc'), (56, 'tladstone'), (57, 'Tarneit'), (60, 'Lalon'), (60, 'rrankston Eakt'), (62, 'Bathucst'), (67, 'kelton'), (71, 'zreston'), (80, 'jrunceston')]\n",
      "Best M=jrunceston\n",
      "result [(75, 'Bkllarat'), (75, 'Maroabra'), (75, 'Narafgba'), (75, 'Parauatta'), (75, 'SurferquParaxise'), (75, 'Traralgon'), (100, 'Lara')]\n",
      "Best M=Lara\n",
      "result [(60, 'Lalon'), (60, 'waree'), (62, 'Engadine'), (80, 'Lxngwarvin')]\n",
      "Best M=Lxngwarvin\n",
      "result [(60, 'Caloundfa'), (60, 'Endlayour dills'), (60, 'Gawlnr'), (60, 'Gleoroy'), (60, 'Ktlgofrlie'), (60, 'Malvyrn Easq'), (60, 'Melbournk'), (60, 'Shaford'), (60, 'Tamwortp'), (60, 'Traralgon'), (80, 'Lalon')]\n",
      "Best M=Lalon\n",
      "result [(64, 'Greensuoroumh'), (64, 'Mafyborougc'), (67, 'Kew'), (82, 'Keysborpugo')]\n",
      "Best M=Keysborpugo\n",
      "result [(67, 'Betwick'), (67, 'Caeberwhll'), (67, 'Keysborpugo'), (67, 'Kwinana'), (67, 'Newcassle'), (100, 'Kew')]\n",
      "Best M=Kew\n",
      "result [(88, 'Katoomoa')]\n",
      "Best M=Katoomoa\n",
      "result [(57, 'Doncasber'), (57, 'Thornmury'), (71, 'ihornbury'), (86, 'Hoansby')]\n",
      "Best M=Hoansby\n",
      "result [(83, 'Hosart')]\n",
      "Best M=Hosart\n",
      "result [(56, 'Thornmury'), (56, 'ihornbury'), (57, 'Clayhon'), (57, 'Narhe Wlroen South'), (57, 'Wantirna Sopqh'), (64, 'Frwkkstln South'), (86, 'Hankhorn South')]\n",
      "Best M=Hankhorn South\n",
      "result [(56, 'Degr Park'), (58, 'Cwty of Parkamctta'), (58, 'rrankston Eakt'), (83, 'HamptonxPare')]\n",
      "Best M=HamptonxPare\n",
      "result [(88, 'zriffith')]\n",
      "Best M=zriffith\n",
      "result [(55, 'Mafyborougc'), (56, 'Dandenoug'), (60, 'waree'), (64, 'Keysborpugo'), (85, 'Greensuoroumh')]\n",
      "Best M=Greensuoroumh\n",
      "result [(56, 'Marrickvicle'), (56, 'Tofnsvdlle'), (56, 'kremantle'), (57, 'Boronil'), (67, 'Orangv'), (89, 'Granvilld')]\n",
      "Best M=Granvilld\n",
      "result [(53, 'CoffswHurbour'), (62, 'Melbournk'), (67, 'Aubuzn'), (67, 'ilbury'), (88, 'Gsulburn')]\n",
      "Best M=Gsulburn\n",
      "result [(53, 'Poidt Cook'), (55, 'Cobutg'), (80, 'fold Czast')]\n",
      "Best M=fold Czast\n",
      "result [(57, 'Gleufercie'), (57, 'alenmfre Park'), (57, 'iount Galbier'), (57, 'palmermton'), (67, 'Gawlnr'), (71, 'GlenjIris'), (86, 'Gleoroy')]\n",
      "Best M=Gleoroy\n",
      "result [(53, 'Ktlgofrlie'), (57, 'Gleoroy'), (60, 'alenmfre Park'), (67, 'GlenjIris'), (71, 'Werribme'), (80, 'Gleufercie')]\n",
      "Best M=Gleufercie\n",
      "result [(56, 'Geraldgon'), (56, 'Thmmdstown'), (56, 'rrankston Eakt'), (57, 'Clayhon'), (57, 'Clayjon'), (57, 'zreston'), (59, 'South Grscton'), (67, 'Moe'), (89, 'tladstone')]\n",
      "Best M=tladstone\n",
      "result [(57, 'Geraldgon'), (57, 'Greensuoroumh'), (57, 'Wollodgfng'), (57, 'iandenong Nogeh'), (60, 'Lalon'), (62, 'Busseeton'), (67, 'kelton'), (86, 'Gielong')]\n",
      "Best M=Gielong\n",
      "result [(54, 'BrightongEasl'), (56, 'Bhacktown'), (56, 'tladstone'), (57, 'Dbnpaster East'), (57, 'Forstlr'), (57, 'Frwkkstln South'), (57, 'zreston'), (60, 'jrunceston'), (67, 'Bankstjwn'), (67, 'kelton'), (86, 'rrankston Eakt'), (89, 'Frankstoc')]\n",
      "Best M=Frankstoc\n",
      "result [(56, 'Bhacktown'), (56, 'Forest aoke'), (56, 'Hankhorn South'), (56, 'South Grscton'), (56, 'tladstone'), (57, 'Forstlr'), (57, 'zreston'), (67, 'Bankstjwn'), (67, 'Frwkkstln South'), (67, 'jrunceston'), (67, 'kelton'), (89, 'Frankstoc'), (89, 'rrankston Eakt')]\n",
      "Best M=rrankston Eakt\n",
      "result [(57, 'Dbnpaster East'), (57, 'Ferntree dwlly'), (57, 'Frankstoc'), (57, 'Frwkkstln South'), (71, 'Forest aoke'), (86, 'Forstlr')]\n",
      "Best M=Forstlr\n",
      "result [(62, 'Busseeton'), (88, 'Essandon')]\n",
      "Best M=Essandon\n",
      "result [(67, 'kphingvale'), (83, 'Emping'), (83, 'Epsing')]\n",
      "Best M=Epsing\n",
      "result [(67, 'kphingvale'), (83, 'Emping'), (83, 'Epsing')]\n",
      "Best M=Epsing\n",
      "result [(53, 'kphingvale'), (53, 'worningtin'), (55, 'Spdney'), (62, 'Lxngwarvin'), (67, 'nairns'), (100, 'Engadine')]\n",
      "Best M=Engadine\n",
      "result [(55, 'Mount Elwda'), (67, 'Cheltdhham'), (67, 'qaulkham Hells'), (83, 'Elthao')]\n",
      "Best M=Elthao\n",
      "result [(83, 'Echucq')]\n",
      "Best M=Echucq\n",
      "result [(53, 'Mount Elwda'), (60, 'Lalon'), (88, 'Esrlwood')]\n",
      "Best M=Esrlwood\n",
      "result [(60, 'CoffswHurbour'), (80, 'Dudbo')]\n",
      "Best M=Dudbo\n",
      "result [(52, 'Malvyrn Easq'), (86, 'Dbnpaster East'), (89, 'Doncasber')]\n",
      "Best M=Doncasber\n",
      "result [(78, 'Dbnpaster East'), (89, 'Doncasber')]\n",
      "Best M=Doncasber\n",
      "result [(89, 'Devorport')]\n",
      "Best M=Devorport\n",
      "result [(56, 'Cwty of Parkamctta'), (56, 'RoxburghcPark'), (56, 'SurferquParaxise'), (57, 'Dee lhy'), (67, 'alenmfre Park'), (89, 'Degr Park')]\n",
      "Best M=Degr Park\n",
      "result [(56, 'Busseeton'), (57, 'zreston'), (67, 'kelton'), (85, 'Depeptivn Bay')]\n",
      "Best M=Depeptivn Bay\n",
      "result [(56, 'Canning qalq'), (57, 'Gielong'), (62, 'Essandon'), (62, 'Wodongf'), (89, 'Dandenoug'), (89, 'iandenong Nogeh')]\n",
      "Best M=iandenong Nogeh\n",
      "result [(57, 'Boronil'), (57, 'Whyrlla'), (88, 'Cuonulla')]\n",
      "Best M=Cuonulla\n",
      "result [(56, 'Caloundfa'), (56, 'Melbournk'), (56, 'ihornbury'), (57, 'Bunbuey'), (62, 'Canberrn'), (70, 'Cabowleure'), (73, 'Burnfe'), (80, 'Caanyourne'), (80, 'Crfniourne')]\n",
      "Best M=Crfniourne\n",
      "result [(56, 'Caloundfa'), (56, 'Melbournk'), (56, 'ihornbury'), (57, 'Bunbuey'), (62, 'Canberrn'), (70, 'Cabowleure'), (73, 'Burnfe'), (80, 'Caanyourne'), (80, 'Crfniourne')]\n",
      "Best M=Crfniourne\n",
      "result [(56, 'Caringblh'), (59, 'Melbournk'), (67, 'ilbury'), (82, 'Craigibbzrn')]\n",
      "Best M=Craigibbzrn\n",
      "result [(55, 'ilbury'), (57, 'Mabdurah'), (85, 'CoffswHurbour')]\n",
      "Best M=CoffswHurbour\n",
      "result [(83, 'Cobutg'), (83, 'RoxburghcPark')]\n",
      "Best M=RoxburghcPark\n",
      "result [(57, 'Bhacktown'), (57, 'Caanyourne'), (57, 'Caloundfa'), (57, 'Endlayour dills'), (57, 'HamptonxPare'), (57, 'Rocuhahpton'), (57, 'Willethon'), (57, 'rrankston Eakt'), (60, 'Lalon'), (67, 'kelton'), (71, 'tladstone'), (86, 'Clayhon'), (86, 'Clayjon')]\n",
      "Best M=Clayjon\n",
      "result [(56, 'Willethon'), (57, 'Gielong'), (60, 'Lalon'), (71, 'Wodongf'), (80, 'Wollodgfng')]\n",
      "Best M=Wollodgfng\n",
      "result [(88, 'Cesznock')]\n",
      "Best M=Cesznock\n",
      "result [(55, 'Bckken Hill'), (64, 'udelaixe Hills'), (73, 'Qzasers Hill'), (82, 'gastlenHill')]\n",
      "Best M=gastlenHill\n",
      "result [(83, 'Carrum Doods')]\n",
      "Best M=Carrum Doods\n",
      "result [(53, 'Thyrnlie'), (60, 'waree'), (62, 'Caringblh'), (71, 'Tarneit'), (88, 'Carnegge'), (88, 'aarnegie')]\n",
      "Best M=aarnegie\n",
      "result [(56, 'Caloundfa'), (56, 'Traralgon'), (57, 'Shaford'), (60, 'Lalon'), (62, 'Carnegge'), (67, 'Caringblh'), (82, 'Carlwxgford')]\n",
      "Best M=Carlwxgford\n",
      "result [(56, 'Canning qalq'), (56, 'Craigibbzrn'), (56, 'Czrindale'), (56, 'Wangarbtaa'), (56, 'eoppeis Croswing'), (60, 'kmina'), (62, 'Carnegge'), (62, 'Narafgba'), (89, 'Caringblh')]\n",
      "Best M=Caringblh\n",
      "result [(53, 'Bunxaberg'), (55, 'Nerana'), (57, 'Doncasber'), (57, 'iount Galbier'), (62, 'Caeberwhll'), (88, 'Canberrn')]\n",
      "Best M=Canberrn\n",
      "result [(60, 'Cabowleure'), (62, 'Canberrn'), (67, 'Kew'), (80, 'Caeberwhll')]\n",
      "Best M=Caeberwhll\n",
      "result [(56, 'Caanyourne'), (56, 'Cabowleure'), (57, 'Bundoosa'), (57, 'Clayhon'), (57, 'Clayjon'), (57, 'qildura'), (62, 'Sundury'), (80, 'Lalon'), (89, 'Caloundfa')]\n",
      "Best M=Caloundfa\n",
      "result [(67, 'Canning qalq'), (67, 'Caringblh'), (67, 'Carnegge'), (83, 'nairns')]\n",
      "Best M=nairns\n",
      "result [(60, 'Caanyourne'), (80, 'Cabowleure')]\n",
      "Best M=Cabowleure\n",
      "result [(55, 'Melbournk'), (67, 'Boronil'), (67, 'Bunbuey'), (67, 'Crfniourne'), (67, 'Post Macquarie'), (67, 'Thyrnlie'), (67, 'aarnegie'), (67, 'burrav Bridge'), (73, 'Caanyourne'), (83, 'Burnfe')]\n",
      "Best M=Burnfe\n",
      "result [(53, 'Canberrn'), (59, 'Doncasber'), (60, 'Dudbo'), (62, 'Bundoosa'), (71, 'Bunbuey'), (89, 'Bunxaberg')]\n",
      "Best M=Bunxaberg\n",
      "result [(57, 'Gleufercie'), (57, 'Werribme'), (57, 'udelaixe Hills'), (86, 'Baderim')]\n",
      "Best M=Baderim\n",
      "result [(56, 'Brwcknn Ridge'), (57, 'Betwick'), (57, 'Boronil'), (62, 'Ranywick'), (89, 'Brunswivk')]\n",
      "Best M=Brunswivk\n",
      "result [(55, 'Brwcknn Ridge'), (55, 'Qzasers Hill'), (55, 'udelaixe Hills'), (57, 'Boronil'), (57, 'gastlenHill'), (67, 'Moe'), (82, 'Bckken Hill')]\n",
      "Best M=Bckken Hill\n",
      "result [(53, 'Werribme'), (75, 'South irisbake'), (88, 'Btisbane')]\n",
      "Best M=Btisbane\n",
      "result [(57, 'Brunswivk'), (57, 'worningtin'), (86, 'Boronil')]\n",
      "Best M=Boronil\n",
      "result [(56, 'rrankston Eakt'), (56, 'tladstone'), (67, 'Bankstjwn'), (67, 'kelton'), (89, 'Bhacktown')]\n",
      "Best M=Bhacktown\n",
      "result [(57, 'Baderim'), (57, 'Brunswivk'), (57, 'Marrickvicle'), (57, 'Ranywick'), (67, 'Kew'), (71, 'Brwcknn Ridge'), (86, 'Betwick')]\n",
      "Best M=Betwick\n",
      "result [(57, 'BrightongEasl'), (57, 'Bundoosa'), (57, 'Geraldgon'), (86, 'Bmndigo')]\n",
      "Best M=Bmndigo\n",
      "result [(55, 'Bckken Hill'), (62, 'Hillsidu'), (64, 'udelaixe Hills'), (86, 'qaulkham Hells')]\n",
      "Best M=qaulkham Hells\n",
      "result [(62, 'South Grscton'), (88, 'Bathucst')]\n",
      "Best M=Bathucst\n",
      "result [(60, 'Noqra'), (83, 'Binoza Point')]\n",
      "Best M=Binoza Point\n",
      "result [(56, 'Busseeton'), (56, 'Hankhorn South'), (56, 'Thmmdstown'), (56, 'tladstone'), (57, 'zreston'), (59, 'jrunceston'), (67, 'kelton'), (71, 'Frankstoc'), (78, 'Bhacktown'), (78, 'rrankston Eakt'), (89, 'Bankstjwn')]\n",
      "Best M=Bankstjwn\n",
      "result [(53, 'Maroabra'), (75, 'Lara'), (88, 'Bkllarat')]\n",
      "Best M=Bkllarat\n",
      "result [(67, 'CoffswHurbour'), (67, 'Melbournk'), (83, 'Aubuzn'), (83, 'Gsulburn')]\n",
      "Best M=Gsulburn\n",
      "result [(62, 'Mohayfkeld'), (88, 'jshfield')]\n",
      "Best M=jshfield\n",
      "result [(53, 'Wotdridge'), (53, 'burrav Bridge'), (60, 'kmina'), (62, 'kremantle'), (75, 'Armakale'), (75, 'Czrindale'), (88, 'Acmidale')]\n",
      "Best M=Acmidale\n",
      "result [(67, 'Gsulburn'), (67, 'Melbournk'), (67, 'ihornbury'), (83, 'ilbury')]\n",
      "Best M=ilbury\n",
      "result [(56, 'Smuthport'), (69, 'South Grscton'), (86, 'South irisbake'), (88, 'Btisbane')]\n",
      "Best M=Btisbane\n",
      "result [(67, 'kelton'), (80, 'Cheltdhham')]\n",
      "Best M=Cheltdhham\n",
      "result [(57, 'Betwick'), (88, 'Ranywick')]\n",
      "Best M=Ranywick\n",
      "result [(86, 'Dee lhy')]\n",
      "Best M=Dee lhy\n",
      "result [(60, 'Acmidale'), (60, 'Czrindale'), (60, 'Emping'), (60, 'Kwinana'), (60, 'Sunshineavest'), (60, 'Wantirna Sopqh'), (60, 'kphingvale'), (80, 'kmina')]\n",
      "Best M=kmina\n",
      "result [(56, 'Willethon'), (57, 'Gleoroy'), (59, 'tladstone'), (60, 'Pertx'), (67, 'kelton'), (71, 'zreston'), (80, 'palmermton')]\n",
      "Best M=palmermton\n",
      "result [(54, 'burrav Bridge'), (56, 'Bhacktown'), (64, 'Bckken Hill'), (85, 'Brwcknn Ridge')]\n",
      "Best M=Brwcknn Ridge\n",
      "result [(56, 'Northcotp'), (60, 'Noqra'), (80, 'Nxrth fyde')]\n",
      "Best M=Nxrth fyde\n",
      "result [(56, 'Caringblh'), (67, 'Epsing'), (81, 'eoppeis Croswing')]\n",
      "Best M=eoppeis Croswing\n",
      "result [(57, 'Tarneit'), (60, 'Lalon'), (90, 'Logan Cits')]\n",
      "Best M=Logan Cits\n",
      "result [(56, 'Caloundfa'), (56, 'burrav Bridge'), (56, 'kphingvale'), (60, 'kmina'), (62, 'Acmidale'), (67, 'Caringblh'), (89, 'Czrindale')]\n",
      "Best M=Czrindale\n",
      "result [(53, 'Armakale'), (75, 'Lara'), (78, 'Cwty of Parkamctta'), (89, 'Parauatta')]\n",
      "Best M=Parauatta\n",
      "result [(57, 'Dee lhy'), (57, 'Forstlr'), (60, 'Pertx'), (60, 'waree'), (86, 'Ferntree dwlly')]\n",
      "Best M=Ferntree dwlly\n",
      "result [(78, 'Parauatta'), (83, 'Cwty of Parkamctta')]\n",
      "Best M=Cwty of Parkamctta\n",
      "result [(55, 'Bckken Hill'), (55, 'gastlenHill'), (57, 'Baderim'), (57, 'Endlayour dills'), (58, 'Qzasers Hill'), (62, 'Hillsidu'), (86, 'udelaixe Hills'), (88, 'Adelakde')]\n",
      "Best M=Adelakde\n",
      "result [(56, 'Caringblh'), (56, 'Czrindale'), (60, 'kphingvale'), (83, 'Canning qalq')]\n",
      "Best M=Canning qalq\n",
      "result [(56, 'GlenjIris'), (60, 'Forest aoke'), (67, 'Degr Park'), (67, 'Moe'), (71, 'Gleoroy'), (85, 'alenmfre Park')]\n",
      "Best M=alenmfre Park\n",
      "result [(56, 'Gleufercie'), (57, 'Gleoroy'), (89, 'GlenjIris')]\n",
      "Best M=GlenjIris\n",
      "result [(56, 'Northcotp'), (60, 'Noqra'), (83, 'Bglwyn Noath')]\n",
      "Best M=Bglwyn Noath\n",
      "result [(53, 'Thyrnlie'), (60, 'waree'), (62, 'Caringblh'), (71, 'Tarneit'), (88, 'Carnegge'), (88, 'aarnegie')]\n",
      "Best M=aarnegie\n",
      "result [(70, 'Dbnpaster East'), (83, 'Malvyrn Easq')]\n",
      "Best M=Malvyrn Easq\n",
      "result [(56, 'Bhacktown'), (57, 'Bmndigo'), (57, 'zreston'), (62, 'rrankston Eakt'), (85, 'BrightongEasl')]\n",
      "Best M=BrightongEasl\n",
      "result [(55, 'Bundoosa'), (83, 'Boovae')]\n",
      "Best M=Boovae\n",
      "result [(56, 'PortwStlphens'), (67, 'Aybany'), (67, 'Saint tlbass'), (89, 'St qlbans')]\n",
      "Best M=St qlbans\n",
      "result [(55, 'Bckken Hill'), (56, 'Dandenoug'), (57, 'Boronil'), (58, 'Qzasers Hill'), (64, 'udelaixe Hills'), (77, 'Hillsidu'), (80, 'Endlayour dills')]\n",
      "Best M=Endlayour dills\n",
      "result [(57, 'Bhacktown'), (57, 'Caanyourne'), (57, 'Caloundfa'), (57, 'Endlayour dills'), (57, 'HamptonxPare'), (57, 'Rocuhahpton'), (57, 'Willethon'), (57, 'rrankston Eakt'), (60, 'Lalon'), (67, 'kelton'), (71, 'tladstone'), (86, 'Clayhon'), (86, 'Clayjon')]\n",
      "Best M=Clayjon\n",
      "result [(60, 'Lalon'), (67, 'Forest aoke'), (85, 'Taysgrs Lakes')]\n",
      "Best M=Taysgrs Lakes\n",
      "result [(67, 'Cobutg'), (67, 'Degr Park'), (92, 'RoxburghcPark')]\n",
      "Best M=RoxburghcPark\n",
      "result [(83, 'WyndhamjVate')]\n",
      "Best M=WyndhamjVate\n",
      "result [(56, 'Wollodgfng'), (56, 'palmermton'), (57, 'zreston'), (67, 'kelton'), (89, 'Willethon')]\n",
      "Best M=Willethon\n",
      "result [(56, 'Hankhorn South'), (57, 'Bunbuey'), (57, 'Hoansby'), (57, 'Sundury'), (67, 'ilbury'), (89, 'Thornmury'), (89, 'ihornbury')]\n",
      "Best M=ihornbury\n",
      "result [(57, 'Boronil'), (57, 'Caanyourne'), (57, 'Crfniourne'), (57, 'Tarneit'), (62, 'Ktlgofrlie'), (62, 'Thornmury'), (88, 'Thyrnlie')]\n",
      "Best M=Thyrnlie\n",
      "result [(62, 'udelaixe Hills'), (88, 'Hillsidu')]\n",
      "Best M=Hillsidu\n",
      "result [(55, 'Boovae'), (57, 'Bmndigo'), (57, 'Caloundfa'), (57, 'Sundury'), (60, 'Dudbo'), (60, 'Noqra'), (88, 'Bundoosa')]\n",
      "Best M=Bundoosa\n",
      "result [(57, 'zreston'), (64, 'Taysgrs Lakes'), (71, 'Forstlr'), (91, 'Forest aoke')]\n",
      "Best M=Forest aoke\n",
      "result [(55, 'Bckken Hill'), (55, 'gastlenHill'), (56, 'Granvilld'), (57, 'Sundury'), (57, 'udelaixe Hills'), (67, 'Aybany'), (77, 'Hillsidu'), (80, 'SunnybinkyHulls'), (89, 'Sunnyback')]\n",
      "Best M=Sunnyback\n",
      "result [(53, 'Frwkkstln South'), (55, 'Warrnamboop'), (57, 'Wantirna Sopqh'), (60, 'waree'), (64, 'Hankhorn South'), (83, 'Namrs Warren'), (83, 'Narhe Wlroen South')]\n",
      "Best M=Narhe Wlroen South\n",
      "result [(56, 'Northcotp'), (57, 'Gielong'), (57, 'Hankhorn South'), (57, 'Wodongf'), (60, 'Noqra'), (62, 'Essandon'), (80, 'iandenong Nogeh'), (89, 'Dandenoug')]\n",
      "Best M=Dandenoug\n",
      "result [(56, 'Bhacktown'), (56, 'tladstone'), (57, 'Forstlr'), (57, 'Wantirna Sopqh'), (57, 'zreston'), (60, 'Narhe Wlroen South'), (60, 'jrunceston'), (67, 'Bankstjwn'), (67, 'kelton'), (71, 'rrankston Eakt'), (79, 'Hankhorn South'), (80, 'Frwkkstln South'), (89, 'Frankstoc')]\n",
      "Best M=Frankstoc\n",
      "result [(85, 'Sunshineavest')]\n",
      "Best M=Sunshineavest\n",
      "result [(67, 'Moe'), (67, 'kelton'), (86, 'Alpona Meddows')]\n",
      "Best M=Alpona Meddows\n",
      "result [(57, 'zreston'), (83, 'Wevt Pennast')]\n",
      "Best M=Wevt Pennast\n",
      "['Whyrlla', 'Rocpbngham', 'Pronpect', 'Pork Hedlanw', 'Pertx', 'burrav Bridge', 'MountmIsa', 'MorphetutVale', 'Mabdurah', 'Kwinana', 'Ktlgofrlie', 'Gvsnells', 'Geraldgon', 'Gawlnr', 'kremantle', 'Dzrwin', 'Busseeton', 'Bunbuey', 'Armakale', 'Adice Sprbngs', 'Aybany', 'Adelakde', 'Wotdridge', 'Wodongf', 'Werribme', 'Warrnamboop', 'Wantirna Sopqh', 'Wangarbtaa', 'Wagga tanga', 'Traralgon', 'Tofnsvdlle', 'Toowoomta', 'ihornbury', 'Thmmdstown', 'Tarneit', 'waree', 'Tamwortp', 'Spdney', 'SurferquParaxise', 'SunnybinkyHulls', 'Sundury', 'PortwStlphens', 'kphingvale', 'Smuthport', 'South Grscton', 'Shepptrtov', 'Shaford', 'SaintoKildn', 'Saint tlbass', 'Rowvijle', 'Rocuhahpton', 'Rimhmond', 'Rgservoir', 'Queanheyab', 'Qzasers Hill', 'zreston', 'Post Macquarie', 'Poidt Cook', 'Pakenham houtq', 'Orangv', 'Noqra', 'Northcotp', 'NoblevParh', 'Newcassle', 'Nerana', 'Namrs Warren', 'Narafgba', 'Mulsrave', 'Mount Martrj', 'iount Galbier', 'Mount Elwda', 'Mosmae', 'worningtin', 'Mohayfkeld', 'Moe', 'Mill dark', 'qildura', 'kelton', 'Melbournk', 'Mafyborougc', 'Marrickvicle', 'Maroabra', 'Mkitland', 'Mawkay', 'Livergool', 'Lismorl', 'Lilydfle', 'jrunceston', 'Lara', 'Lxngwarvin', 'Lalon', 'Keysborpugo', 'Kew', 'Katoomoa', 'Hoansby', 'Hosart', 'Hankhorn South', 'HamptonxPare', 'zriffith', 'Greensuoroumh', 'Granvilld', 'Gsulburn', 'fold Czast', 'Gleoroy', 'Gleufercie', 'tladstone', 'Gielong', 'Frankstoc', 'rrankston Eakt', 'Forstlr', 'Essandon', 'Epsing', 'Epsing', 'Engadine', 'Elthao', 'Echucq', 'Esrlwood', 'Dudbo', 'Doncasber', 'Doncasber', 'Devorport', 'Degr Park', 'Depeptivn Bay', 'iandenong Nogeh', 'Cuonulla', 'Crfniourne', 'Crfniourne', 'Craigibbzrn', 'CoffswHurbour', 'RoxburghcPark', 'Clayjon', 'Wollodgfng', 'Cesznock', 'gastlenHill', 'Carrum Doods', 'aarnegie', 'Carlwxgford', 'Caringblh', 'Canberrn', 'Caeberwhll', 'Caloundfa', 'nairns', 'Cabowleure', 'Burnfe', 'Bunxaberg', 'Baderim', 'Brunswivk', 'Bckken Hill', 'Btisbane', 'Boronil', 'Bhacktown', 'Betwick', 'Bmndigo', 'qaulkham Hells', 'Bathucst', 'Binoza Point', 'Bankstjwn', 'Bkllarat', 'Gsulburn', 'jshfield', 'Acmidale', 'ilbury', 'Btisbane', 'Cheltdhham', 'Ranywick', 'Dee lhy', 'kmina', 'palmermton', 'Brwcknn Ridge', 'Nxrth fyde', 'eoppeis Croswing', 'Logan Cits', 'Czrindale', 'Parauatta', 'Ferntree dwlly', 'Cwty of Parkamctta', 'Adelakde', 'Canning qalq', 'alenmfre Park', 'GlenjIris', 'Bglwyn Noath', 'aarnegie', 'Malvyrn Easq', 'BrightongEasl', 'Boovae', 'St qlbans', 'Endlayour dills', 'Clayjon', 'Taysgrs Lakes', 'RoxburghcPark', 'WyndhamjVate', 'Willethon', 'ihornbury', 'Thyrnlie', 'Hillsidu', 'Bundoosa', 'Forest aoke', 'Sunnyback', 'Narhe Wlroen South', 'Dandenoug', 'Frankstoc', 'Sunshineavest', 'Alpona Meddows', 'Wevt Pennast']\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from fuzzywuzzy import fuzz\n",
    "from fuzzywuzzy import process\n",
    "\n",
    "df1=df['correctname']\n",
    "df2=df['wrongname']\n",
    "\n",
    "df1.columns=['correctname']\n",
    "df2.columns=['wrongname']\n",
    "\n",
    "def match(Col1,Col2):\n",
    "    overall=[]\n",
    "    for n in Col1:\n",
    "        result=[(fuzz.partial_ratio(n, n2),n2) \n",
    "                for n2 in Col2 if fuzz.partial_ratio(n, n2)>50\n",
    "               ]\n",
    "        if len(result):\n",
    "            result.sort()    \n",
    "            print('result {}'.format(result))\n",
    "            print(\"Best M={}\".format(result[-1][1]))\n",
    "            overall.append(result[-1][1])\n",
    "        else:\n",
    "            overall.append(\" \")\n",
    "    return overall\n",
    "\n",
    "print(match(df1,df2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Problem 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Part - 1: Given a list of sentences (list_of_setences.txt) write an algorithm which computes the semantic similarity and return the similar sentences together.\n",
    "\n",
    "Semantic similarity is a metric defined over a set of documents or terms, where the idea of distance between them is based on the likeness of their meaning or semantic content.\n",
    "\n",
    "For example : \"Football is played in Brazil\" and \"Cricket is played in India\". Both these sentences are about sports so they will have a semantic similarity.\n",
    "\n",
    "Part - 2: Extend the above algorithm in form of a REST API. The input parameter is a list of sentences (refer to the file list_of_setences.txt) and the response is a list of list with the similar sentences.\n",
    "\n",
    "For example : Say there are 4 sentences as an input list - [\"Football is played in Brazil\" , \"Cricket is played in India\", \"Traveling is good for health\", \"People love traveling in winter\"]\n",
    "\n",
    "Output : [[\"Football is played in Brazil\" , \"Cricket is played in India\"], [\"Traveling is good for health\", \"People love traveling in winter\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import wordnet as wn\n",
    "from subprocess import check_output\n",
    "from nltk import word_tokenize\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import math\n",
    "import nltk\n",
    "import re\n",
    "from nltk import word_tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# listOfSentences = pd.read_csv('list_of_sentences.txt')\n",
    "documents = [\n",
    "    \"good morning\",\n",
    "    \"how are you doing ?\",\n",
    "    \"the weather is awesome today\",\n",
    "    \"samsung\",\n",
    "    \"good afternoon\",\n",
    "    \"baseball is played in the USA\",\n",
    "    \"there is a thunderstorm\",\n",
    "    \"are you doing good ?\",\n",
    "    \"The polar regions are melting\",\n",
    "    \"apple\",\n",
    "    \"nokia\",\n",
    "    \"cricket is a fun game\",\n",
    "    \"the climate change is a problem\",\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['good morning',\n",
       " 'how are you doing ?',\n",
       " 'the weather is awesome today',\n",
       " 'samsung',\n",
       " 'good afternoon',\n",
       " 'baseball is played in the USA',\n",
       " 'there is a thunderstorm',\n",
       " 'are you doing good ?',\n",
       " 'The polar regions are melting',\n",
       " 'apple',\n",
       " 'nokia',\n",
       " 'cricket is a fun game',\n",
       " 'the climate change is a problem']"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "documents"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Approach 1:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using gensim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "from gensim import corpora"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove common words and tokenize\n",
    "stoplist = set('for a of the and to in'.split())\n",
    "texts = [\n",
    "    [word for word in document.lower().split() if word not in stoplist]\n",
    "    for document in documents\n",
    "]\n",
    "\n",
    "# remove words that appear only once\n",
    "frequency = defaultdict(int)\n",
    "for text in texts:\n",
    "    for token in text:\n",
    "        frequency[token] += 1\n",
    "\n",
    "texts = [\n",
    "    [token for token in text if frequency[token] > 1]\n",
    "    for text in texts\n",
    "]\n",
    "\n",
    "dictionary = corpora.Dictionary(texts)\n",
    "corpus = [dictionary.doc2bow(text) for text in texts]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[(0, 1)],\n",
       " [(1, 1), (2, 1), (3, 1), (4, 1)],\n",
       " [(5, 1)],\n",
       " [],\n",
       " [(0, 1)],\n",
       " [(5, 1)],\n",
       " [(5, 1)],\n",
       " [(0, 1), (1, 1), (2, 1), (3, 1), (4, 1)],\n",
       " [(2, 1)],\n",
       " [],\n",
       " [],\n",
       " [(5, 1)],\n",
       " [(5, 1)]]"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim import models\n",
    "lsi = models.LsiModel(corpus, id2word=dictionary, num_topics=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(1, -0.9999999999999994)]\n"
     ]
    }
   ],
   "source": [
    "doc = \"cricket is a fun game\"\n",
    "vec_bow = dictionary.doc2bow(doc.lower().split())\n",
    "vec_lsi = lsi[vec_bow]  # convert the query to LSI space\n",
    "print(vec_lsi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim import similarities\n",
    "index = similarities.MatrixSimilarity(lsi[corpus])  # transform corpus to LSI space and index it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(0, 0.0), (1, 0.0), (2, 1.0), (3, 0.0), (4, 0.0), (5, 1.0), (6, 1.0), (7, 0.0), (8, 0.0), (9, 0.0), (10, 0.0), (11, 1.0), (12, 1.0)]\n"
     ]
    }
   ],
   "source": [
    "sims = index[vec_lsi]  # perform a similarity query against the corpus\n",
    "print(list(enumerate(sims)))  # print (document_number, document_similarity) 2-tuples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2, 1.0) good morning\n",
      "(5, 1.0) how are you doing ?\n",
      "(6, 1.0) the weather is awesome today\n",
      "(11, 1.0) samsung\n",
      "(12, 1.0) good afternoon\n",
      "(0, 0.0) baseball is played in the USA\n",
      "(1, 0.0) there is a thunderstorm\n",
      "(3, 0.0) are you doing good ?\n",
      "(4, 0.0) The polar regions are melting\n",
      "(7, 0.0) apple\n",
      "(8, 0.0) nokia\n",
      "(9, 0.0) cricket is a fun game\n",
      "(10, 0.0) the climate change is a problem\n"
     ]
    }
   ],
   "source": [
    "sims = sorted(enumerate(sims), key=lambda item: -item[1])\n",
    "for i, s in enumerate(sims):\n",
    "    print(s, documents[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Approcah 2: --ignored"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import fastsemsim\n",
    "str1='Birthday party ruined as cake explodes'\n",
    "str2='Grandma mistakenly bakes cake using gunpowder'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Semsim(str1,str2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize(q1, q2):\n",
    "    \"\"\"\n",
    "        q1 and q2 are sentences/questions. Function returns a list of tokens for both.\n",
    "    \"\"\"\n",
    "    return word_tokenize(q1), word_tokenize(q2)\n",
    "\n",
    "\n",
    "def posTag(q1, q2):\n",
    "    \"\"\"\n",
    "        q1 and q2 are lists. Function returns a list of POS tagged tokens for both.\n",
    "    \"\"\"\n",
    "    return nltk.pos_tag(q1), nltk.pos_tag(q2)\n",
    "\n",
    "def stemmer(tag_q1, tag_q2):\n",
    "    \"\"\"\n",
    "        tag_q = tagged lists. Function returns a stemmed list.\n",
    "    \"\"\"\n",
    "\n",
    "    stem_q1 = []\n",
    "    stem_q2 = []\n",
    "\n",
    "    for token in tag_q1:\n",
    "        stem_q1.append(stem(token))\n",
    "\n",
    "    for token in tag_q2:\n",
    "        stem_q2.append(stem(token))\n",
    "\n",
    "    return stem_q1, stem_q2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Micheal Lesk Algorithm\n",
    "We are going to use the Micheal Lesk Algorithm for word sense disambugation (WSD). It uses WordNet.\n",
    "\n",
    "- It excludes stop words\n",
    "- The overlap is calculated using the gloss of all the context words such that the most matching sense of the word will be accepted as the best sense of the word in the context."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "    def __init__(self, sentence):\n",
    "        self.sentence = sentence\n",
    "        self.meanings = {}\n",
    "        for word in sentence:\n",
    "            self.meanings[word] = ''\n",
    "\n",
    "    def getSenses(self, word):\n",
    "        # print word\n",
    "        return wn.synsets(word.lower())\n",
    "\n",
    "    def getGloss(self, senses):\n",
    "\n",
    "        gloss = {}\n",
    "\n",
    "        for sense in senses:\n",
    "            gloss[sense.name()] = []\n",
    "\n",
    "        for sense in senses:\n",
    "            gloss[sense.name()] += word_tokenize(sense.definition())\n",
    "\n",
    "        return gloss\n",
    "\n",
    "    def getAll(self, word):\n",
    "        senses = self.getSenses(word)\n",
    "\n",
    "        if senses == []:\n",
    "            return {word.lower(): senses}\n",
    "\n",
    "        return self.getGloss(senses)\n",
    "\n",
    "    def Score(self, set1, set2):\n",
    "        # Base\n",
    "        overlap = 0\n",
    "\n",
    "        # Step\n",
    "        for word in set1:\n",
    "            if word in set2:\n",
    "                overlap += 1\n",
    "\n",
    "        return overlap\n",
    "\n",
    "    def overlapScore(self, word1, word2):\n",
    "\n",
    "        gloss_set1 = self.getAll(word1)\n",
    "        if self.meanings[word2] == '':\n",
    "            gloss_set2 = self.getAll(word2)\n",
    "        else:\n",
    "            # print 'here'\n",
    "            gloss_set2 = self.getGloss([wn.synset(self.meanings[word2])])\n",
    "\n",
    "        # print gloss_set2\n",
    "\n",
    "        score = {}\n",
    "        for i in gloss_set1.keys():\n",
    "            score[i] = 0\n",
    "            for j in gloss_set2.keys():\n",
    "                score[i] += self.Score(gloss_set1[i], gloss_set2[j])\n",
    "\n",
    "        bestSense = None\n",
    "        max_score = 0\n",
    "        for i in gloss_set1.keys():\n",
    "            if score[i] > max_score:\n",
    "                max_score = score[i]\n",
    "                bestSense = i\n",
    "\n",
    "        return bestSense, max_score\n",
    "\n",
    "    def lesk(self, word, sentence):\n",
    "        maxOverlap = 0\n",
    "        context = sentence\n",
    "        word_sense = []\n",
    "        meaning = {}\n",
    "\n",
    "        senses = self.getSenses(word)\n",
    "\n",
    "        for sense in senses:\n",
    "            meaning[sense.name()] = 0\n",
    "\n",
    "        for word_context in context:\n",
    "            if not word == word_context:\n",
    "                score = self.overlapScore(word, word_context)\n",
    "                if score[0] == None:\n",
    "                    continue\n",
    "                meaning[score[0]] += score[1]\n",
    "\n",
    "        if senses == []:\n",
    "            return word, None, None\n",
    "\n",
    "        self.meanings[word] = max(meaning.keys(), key=lambda x: meaning[x])\n",
    "\n",
    "        return word, self.meanings[word], wn.synset(self.meanings[word]).definition()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Two different similarity measures have been used:\n",
    "1. Path similarity which calculates the distance in the words in the hyponym taxonymy graph\n",
    "2. Wup similarity is the Wu & Palmer's similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy import spatial\n",
    "from nltk.corpus import wordnet as wn\n",
    "from nltk.metrics import edit_distance\n",
    "\n",
    "def path(set1, set2):\n",
    "    return wn.path_similarity(set1, set2)\n",
    "\n",
    "\n",
    "def wup(set1, set2):\n",
    "    return wn.wup_similarity(set1, set2)\n",
    "\n",
    "\n",
    "def edit(word1, word2):\n",
    "    if float(edit_distance(word1, word2)) == 0.0:\n",
    "        return 0.0\n",
    "    return 1.0 / float(edit_distance(word1, word2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def computePath(q1, q2):\n",
    "\n",
    "    R = np.zeros((len(q1), len(q2)))\n",
    "\n",
    "    for i in range(len(q1)):\n",
    "        for j in range(len(q2)):\n",
    "            if q1[i][1] == None or q2[j][1] == None:\n",
    "                sim = edit(q1[i][0], q2[j][0])\n",
    "            else:\n",
    "                sim = path(wn.synset(q1[i][1]), wn.synset(q2[j][1]))\n",
    "\n",
    "            if sim == None:\n",
    "                sim = edit(q1[i][0], q2[j][0])\n",
    "\n",
    "            R[i, j] = sim\n",
    "\n",
    "    # print R\n",
    "\n",
    "    return R"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def computeWup(q1, q2):\n",
    "\n",
    "    R = np.zeros((len(q1), len(q2)))\n",
    "\n",
    "    for i in range(len(q1)):\n",
    "        for j in range(len(q2)):\n",
    "            if q1[i][1] == None or q2[j][1] == None:\n",
    "                sim = edit(q1[i][0], q2[j][0])\n",
    "            else:\n",
    "                sim = wup(wn.synset(q1[i][1]), wn.synset(q2[j][1]))\n",
    "\n",
    "            if sim == None:\n",
    "                sim = edit(q1[i][0], q2[j][0])\n",
    "\n",
    "            R[i, j] = sim\n",
    "\n",
    "    # print R\n",
    "\n",
    "    return R"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is the fifth part of the algorithm mentioned below. Combines the similarity measures calculated for the two sentences and produces a single similarity score."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def overallSim(q1, q2, R):\n",
    "\n",
    "    sum_X = 0.0\n",
    "    sum_Y = 0.0\n",
    "\n",
    "    for i in range(len(q1)):\n",
    "        max_i = 0.0\n",
    "        for j in range(len(q2)):\n",
    "            if R[i, j] > max_i:\n",
    "                max_i = R[i, j]\n",
    "        sum_X += max_i\n",
    "\n",
    "    for i in range(len(q1)):\n",
    "        max_j = 0.0\n",
    "        for j in range(len(q2)):\n",
    "            if R[i, j] > max_j:\n",
    "                max_j = R[i, j]\n",
    "        sum_Y += max_j\n",
    "        \n",
    "    if (float(len(q1)) + float(len(q2))) == 0.0:\n",
    "        return 0.0\n",
    "        \n",
    "    overall = (sum_X + sum_Y) / (2 * (float(len(q1)) + float(len(q2))))\n",
    "\n",
    "    return overall"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
